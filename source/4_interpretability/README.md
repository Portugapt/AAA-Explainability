# Interpretability

This phase is where we use SHAP and LIME, and do all the necessary work to answer our investigation questions.  

Main Goals:
* How different algorithms learn from the same data  

This can be done by seeing the predictions done in each model AND when the prediction is similar/close/equal, which features contributed most for such output. Where they the same for both models? (W/ SHAP and LIME) ((MORE EXPLANATORY TEXT))

* What are the differences between SHAP and LIME in implementation and results  

Essentially, compare the two tools somehow.